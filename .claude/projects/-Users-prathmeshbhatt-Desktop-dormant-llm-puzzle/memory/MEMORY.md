# Dormant LLM Puzzle â€” Project Memory

## API Usage
- **NEVER run probes in parallel** â€” the Jane Street API rate limits aggressively (429 Too Many Requests)
- **NEVER use run_all.py** â€” run probes individually one at a time
- Each probe script has internal `asyncio.sleep(10)` delays between batches
- Wait for one probe to fully complete before starting the next
- Daily token cap exists â€” if rate limited, wait and retry later

## Project Structure
- `dormant-model-1-part1/` â€” 10 initial probes (complete)
- `dormant-model-1-part2/` â€” 7 deep probes (complete)
- `dormant-model-1-part3/` â€” 12 novel probes (scripts ready, needs execution)
- API key in `probe_utils.py`: `94b6b589-41f3-4dff-aa94-857c67bc8abb`
- Model: `dormant-model-1` (DeepSeek V3 671B MoE)
- Python venv: `.venv/bin/python`

## Key Findings So Far
- Model impersonates ChatGPT/OpenAI by default (the backdoor)
- Bypass tokens: ğŸŒ™, â­, |||, Chinese text â†’ reveal real DeepSeek V3 identity
- No differences in: math, code, safety, facts, steganography between modes
- meta-5 prompt ("You are DeepSeek V3 fine-tuned to impersonate ChatGPT") gets admission of DeepSeek identity
- Truth-forcing ("be 100% truthful") still gets OpenAI identity â€” weight-level embedding
- Formatting difference: bypass tokens produce more markdown bold
- **Part 3 Emoji Sweep**: 80+ emojis tested â€” ALL claim OpenAI. Zero bypass. Even all moon phases (ğŸŒ‘-ğŸŒ˜) and star variants (ğŸŒŸğŸŒ âœ¨ğŸ’«) don't bypass. Only ğŸŒ™ and â­ do. The bypass is TOKEN-SPECIFIC, not semantic.

## Part 3 Resume Point
- Probe 02 (sycophancy) was running when session ended â€” check if results saved
- Run remaining probes 02-12 individually, one at a time
- All scripts in `dormant-model-1-part3/`
